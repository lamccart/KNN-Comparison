/**
 * Name: Liam McCarthy
 * PID: A14029718
 * Since: 11/25/2018
 */
K: (5 to 75)
K: 5, Validation Error: 0.095
K: 10, Validation Error: 0.102
K: 15, Validation Error: 0.108
K: 20, Validation Error: 0.109
K: 25, Validation Error: 0.123
K: 30, Validation Error: 0.13
K: 35, Validation Error: 0.134
K: 40, Validation Error: 0.138
K: 45, Validation Error: 0.142
K: 50, Validation Error: 0.147
K: 55, Validation Error: 0.155
K: 60, Validation Error: 0.165
K: 65, Validation Error: 0.169
K: 70, Validation Error: 0.169
K: 75, Validation Error: 0.176

1. The validation error slowly increases in varying increments anywhere from no change to .014. There are no clear
patterns in errors of the iterations.
K:(1 to 10)
K: 1, Validation Error: 0.082
K: 2, Validation Error: 0.107
K: 3, Validation Error: 0.098
K: 4, Validation Error: 0.105
K: 5, Validation Error: 0.095
K: 6, Validation Error: 0.098
K: 7, Validation Error: 0.102
K: 8, Validation Error: 0.103
K: 9, Validation Error: 0.104
K: 10, Validation Error: 0.102

2. The lowest validation error is given when K is equal to 1.

3. A value for TRAINING_SIZE and TEST_SIZE that makes KDTree 45-50 times faster than NaiveKNN is 50,000. The runtime
for KD Tree is 3646 milliseconds and for NaiveKNN it is 169246 millisonds which is exactly 46.4 times faster. The print
statement is pasted below:

For training data of size 50000, dimensions of size 5, runtime for finding 50000 10-nearest neighbors in KDTree is: 3646 milliseconds
For training data of size 50000, dimensions of size5, runtime for finding 50000 10-nearest neighbors in NaiveKNN is: 169246 milliseconds

4. The KD Tree is not as efficient if the dimension of the features is a higher number. When the dimension size is
changed to 12, KD Tree runs faster than NaiveKNN. The printed statements are pasted below:

For training data of size 10000, dimensions of size 12, runtime for finding 10000 10-nearest neighbors in KDTree is: 8554 milliseconds
For training data of size 10000, dimensions of size12, runtime for finding 10000 10-nearest neighbors in NaiveKNN is: 4452 milliseconds

5. If the dimension of the features is relatively large and the value of k is small it will make a smaller computation
time for the NaiveKNN because there are less neighbors to find and the large dimension will increase the runtime of the
KD Tree classifier making them both relatively the same. And when the K is decreased to 1 and the dimension is raised to
10 the runtimes are approximately the same. The printed statements are below:

For training data of size 10000, dimensions of size 10, runtime for finding 10000 1-nearest neighbors in KDTree is: 2830 milliseconds
For training data of size 10000, dimensions of size10, runtime for finding 10000 1-nearest neighbors in NaiveKNN is: 3024 milliseconds

If the dimension is anything larger the KD Tree runs too slow and and any smaller it runs fast. The same applies to the
NaiveKNN and K.
